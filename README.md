# Self-Supervised Learning on CIFAR-10  
### Contrastive Learning â€¢ Barlow Twins â€¢ Transfer Learning

Este proyecto implementa un pipeline completo de **aprendizaje supervisado** y **auto-supervisado (SSL)** usando el dataset **CIFAR-10**, explorando cÃ³mo cambia el rendimiento segÃºn la cantidad de datos etiquetados y cÃ³mo un modelo auto-supervisado puede mejorar la generalizaciÃ³n.

---

## ğŸ¯ Objetivos del Proyecto

- Entrenar una red neuronal **supervisada** con distintos porcentajes de datos etiquetados.
- Implementar un pipeline de **Self-Supervised Learning (SSL)** estilo **Barlow Twins**.
- Usar augmentaciones avanzadas para generar dos vistas de la misma imagen.
- Comparar:
  - Entrenamiento desde cero
  - Entrenamiento con pesos preentrenados (ResNet18 pretrained)
  - Fine-tuning de un backbone auto-supervisado
- Visualizar pÃ©rdidas, accuracy y el efecto del SSL.

---

## ğŸ§  Â¿QuÃ© se aprende aquÃ­?

### âœ”ï¸ 1. Cargar y manipular CIFAR-10  
Uso de `torchvision.datasets.CIFAR10`, `Dataset`, `DataLoader` y normalizaciÃ³n.

### âœ”ï¸ 2. Entrenar un modelo supervisado  
- Arquitectura basada en **ResNet18**
- OptimizaciÃ³n con Adam
- CÃ¡lculo de cross entropy y accuracy

### âœ”ï¸ 3. Experimentos con distintas cantidades de datos  
Se entrenan modelos con:
pctgs = [0.01, 0.1, 1.0]

Comparando performance segÃºn la disponibilidad de etiquetas.

### âœ”ï¸ 4. Augmentaciones con Albumentations  
Incluyendo:

- RandomResizedCrop  
- HorizontalFlip  
- ColorJitter  
- ToGray  
- Solarize  

### âœ”ï¸ 5. Self-Supervised Learning (tipo Barlow Twins)  
ImplementaciÃ³n del loss contrastivo usando:

- Dos vistas randomizadas
- NormalizaciÃ³n batch-wise
- Cross-correlation matrix
- PenalizaciÃ³n diagonal vs off-diagonal

### âœ”ï¸ 6. Fine-Tuning desde un backbone Self-Supervised  
El backbone SSL se guarda en TorchScript:

```python
torch.jit.script(SSLmodel.backbone).save("SSLbackbone.pt")

ğŸ§© Requisitos

Antes de ejecutar el script, instala las dependencias:

pip install -r requirements.txt

ğŸ§‘â€ğŸ’» Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
